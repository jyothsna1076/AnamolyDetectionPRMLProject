# Anamolyse
# ğŸš¨ Network Anomaly Detection using Machine Learning

A Comparative Study of Supervised and Unsupervised Models for Intrusion Detection  
**Course Project | Pattern Recognition and Machine Learning (CSL2050)**  
**IIT Jodhpur**

## ğŸ“Œ Overview

This project aims to detect anomalies in network traffic using various machine learning models. We explore and compare six popular algorithmsâ€”Logistic Regression, SVM, Random Forest, KNN, Gaussian Mixture Model (GMM), and Naive Bayesâ€”on a benchmark intrusion detection dataset.

Our goal: **Build an accurate, robust, and scalable Intrusion Detection System (IDS)**.

## âœ¨ Key Highlights

- âœ… Binary classification: **Normal vs Malicious**
- ğŸ“Š Performance evaluated using **Accuracy, Precision, Recall, F1-score**
- ğŸš€ Best performing model: **Random Forest (99.5% Accuracy)**
- ğŸ“ Dataset: Kaggle Network Intrusion Detection Dataset  
  [Link](https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection)

---

## ğŸ§  Models Implemented

| Model                | Accuracy | Precision | Recall | F1-Score | Training Time |
|---------------------|----------|-----------|--------|----------|----------------|
| Logistic Regression | 92.75%   | 95%       | 91%    | 93%      | 4.79 sec       |
| SVM (RBF Kernel)    | 91.2%    | 90.5%     | 89.8%  | 90.1%    | Moderate       |
| Random Forest       | 99.5%    | 99.5%     | 99.5%  | 99.5%    | 0.84 sec       |
| KNN (k=5)           | 88.4%    | 87.2%     | 86.7%  | 86.9%    | Slow           |
| GMM                 | 83.1%    | 81.4%     | 82.0%  | 81.7%    | Moderate       |
| Naive Bayes         | 90.63%   | 88%       | 96%    | 92%      | 0.02 sec       |

---

## ğŸ§ª Dataset Details

- ğŸ“¦ **Total Samples**: 25,192  
- ğŸ”¢ **Features**: 42 (3 categorical, 38 numerical, 1 target)
- ğŸ¯ **Target Classes**: `normal`, `anomaly`

### ğŸ§¹ Preprocessing Steps:
- Label encoding for categorical features
- StandardScaler for feature scaling
- Stratified Train-Test Split (80:20 and 70:30)

---


ğŸ› ï¸ Setup & Usage Instructions (Windows)


1.âœ… Prerequisites
Python 3.7+ must be installed.

For Windows, ensure:

Npcap is installed.

Sudo Mode and Developer Mode are enabled:

Go to Settings â†’ System â†’ For Developers

Enable Developer Mode and Sudo Mode

2.ğŸ“¦ Environment Setup
Create a virtual environment and install dependencies:

```bash
# Clone the repository
git clone https://github.com/jyothsna1076/AnamolyDetectionPRMLProject.git
cd AnamolyDetectionPRMLProject
```

For Windows :
```bash
# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate
```

For Linux :
```bash
# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate
```

```bash
# Install required packages
pip install -r requirements.txt
```

3.ğŸš€ Running the Application

For Windows :
```bash
# Run the app
python app.py
```

For Linux :
```bash
# Run the app(sudo mode is required)
sudo python3 app.py
```

- Open your browser and go to: http://127.0.0.1:5000/
- The web interface will load.

4. ğŸŒ Using the Web Interface
   
Option A: ğŸ“¡ Real-Time Traffic Capture
Click the "Capture Real Traffic" button on the webpage.

Wait approximately 1-1.5 minute for real-time anomaly detection results to appear.

Option B: ğŸ“ Upload CSV Test Data
Upload the file Test_data.csv provided in the repository.

This file contains a large dataset â€” please wait up to 5 minutes for results to process.

âš ï¸ Do not modify any backend files (Python, HTML, etc.) while the app is running in the browser â€” doing so may interrupt processing.

ğŸ“ Notes
For Windows: Make sure Npcap is installed before running the app.

Ensure all developer settings are correctly enabled if you're using Windows.

The app uses live network traffic, so admin/sudo privileges are necessary.

---

## ğŸ“‚ Project Structure

```bash
AnamolyDetectionPRMLProject/
â”œâ”€â”€ jupyter_files/              
â”‚   â”œâ”€â”€ BGMM_model.ipynb
â”‚   â”œâ”€â”€ gaussian_naive_bayes.ipynb
â”‚   â”œâ”€â”€ NIDS_regression.ipynb
â”‚   â”œâ”€â”€ knn_model.ipynb
â”‚   â”œâ”€â”€ gmm_model.ipynb
â”‚   â”œâ”€â”€ naive_bayes.ipynb
â”œâ”€â”€ MidProjectReport
|   â”œâ”€â”€ MidSemReportPRML.pdf
|   â”œâ”€â”€ prml_mid_project.ipynb     
â”œâ”€â”€ python_models
|   â”œâ”€â”€ BGMM_model.py
|   â”œâ”€â”€ LogisticRegression.py
|   â”œâ”€â”€ model_knn.py
|   â”œâ”€â”€ Model.py
|   â”œâ”€â”€ randomforestprml.py
|   â”œâ”€â”€ SVM_best_model.py      
â”œâ”€â”€ app.py
â”œâ”€â”€ capture_script.py
â”œâ”€â”€ index.html
â”œâ”€â”€ predict1.py                
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
â”œâ”€â”€ Train_data.csv
â”œâ”€â”€ Test_data.csv
```

---

## ğŸ‘¥ Team Members & Contributions

| Name                | Contribution                                |
|---------------------|---------------------------------------------|
| Vadlamudi Jyothsna | Random Forest, project documentation        |
| Pradeepika Nori    | SVM implementation, UI integration          |
| Nishu Verma         | Logistic Regression                         |
| BhagyaShree         | KNN implementation                          |
| Reshma Maurya       | Naive Bayes implementation                  |
| Nagma Saj           | Gaussian Mixture Model implementation       |

---

## ğŸ“ˆ Results & Conclusion

Random Forest consistently outperformed other models in both accuracy and generalization. Despite its simplicity, Logistic Regression also performed competitively. Models like KNN and GMM lagged behind in inference time and assumptions.

> âœ… **Takeaway**: Ensemble methods like Random Forest are powerful for IDS tasks due to their robustness and low overfitting tendencies.

---

## ğŸ“œ License

This project is for academic use under the **MIT License**.

---

## ğŸ“ Contact

For queries or collaborations, reach out to:  
ğŸ“§ b23cs1076@iitj.ac.in  
ğŸ“§ b23cs1007@iitj.ac.in  
ğŸ“§ b23cs1034@iitj.ac.in  
ğŸ“§ b23cs1045@iitj.ac.in
ğŸ“§ b23cs1047@iitj.ac.in
ğŸ“§ b23ee1043@iitj.ac.in  


